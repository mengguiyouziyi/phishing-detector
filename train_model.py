#!/usr/bin/env python3
"""
é’“é±¼ç½‘ç«™æ£€æµ‹å™¨è®­ç»ƒè„šæœ¬
é’ˆå¯¹4090æ˜¾å¡ä¼˜åŒ–
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns
import json
import time
import logging
from typing import Dict, List, Any, Tuple
import argparse
from training_config import TrainingConfig, Trainer, AdvancedPhishingDetector, PhishingDataset

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DataProcessor:
    """æ•°æ®å¤„ç†å™¨"""

    def __init__(self):
        self.scaler = StandardScaler()
        self.feature_columns = []

    def load_data(self, filepath: str) -> pd.DataFrame:
        """åŠ è½½æ•°æ®"""
        try:
            if filepath.endswith('.csv'):
                df = pd.read_csv(filepath)
            elif filepath.endswith('.json'):
                df = pd.read_json(filepath)
            else:
                raise ValueError("ä¸æ”¯æŒçš„æ•°æ®æ ¼å¼")

            logger.info(f"æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
            return df

        except Exception as e:
            logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return pd.DataFrame()

    def preprocess_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """é¢„å¤„ç†æ•°æ®"""
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_columns = [col for col in df.columns if col not in ['is_phishing', 'source', 'url']]
        self.feature_columns = feature_columns

        # æå–ç‰¹å¾å’Œæ ‡ç­¾
        X = df[feature_columns].values
        y = df['is_phishing'].values

        # å¤„ç†ç¼ºå¤±å€¼
        X = np.nan_to_num(X)

        # æ ‡å‡†åŒ–
        X = self.scaler.fit_transform(X)

        logger.info(f"ç‰¹å¾æ•°é‡: {X.shape[1]}")
        logger.info(f"æ ·æœ¬æ•°é‡: {X.shape[0]}")
        logger.info(f"æ­£æ ·æœ¬æ¯”ä¾‹: {y.mean():.3f}")

        return X, y

    def split_data(self, X: np.ndarray, y: np.ndarray, test_size: float = 0.2, val_size: float = 0.1) -> Tuple:
        """åˆ†å‰²æ•°æ®"""
        # å…ˆåˆ†å‰²å‡ºæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )

        # å†ä»è®­ç»ƒé›†åˆ†å‰²å‡ºéªŒè¯é›†
        X_train, X_val, y_train, y_val = train_test_split(
            X_train, y_train, test_size=val_size/(1-test_size), random_state=42, stratify=y_train
        )

        logger.info(f"è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
        logger.info(f"éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬")
        logger.info(f"æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")

        return X_train, X_val, X_test, y_train, y_val, y_test

    def create_features_dict(self, X: np.ndarray) -> List[Dict[str, Any]]:
        """åˆ›å»ºç‰¹å¾å­—å…¸"""
        features = []

        for i in range(X.shape[0]):
            # å°†ç‰¹å¾åˆ†æˆä¸åŒçš„ç»„
            features.append({
                'url_features': X[i, :50].tolist(),  # URLç‰¹å¾
                'html_features': X[i, 50:150].tolist(),  # HTMLç‰¹å¾
                'ssl_features': X[i, 150:170].tolist()  # SSLç‰¹å¾
            })

        return features

class ModelEvaluator:
    """æ¨¡å‹è¯„ä¼°å™¨"""

    def __init__(self):
        self.metrics = {}

    def evaluate_model(self, model: nn.Module, test_loader: DataLoader, device: torch.device) -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹"""
        model.eval()
        all_predictions = []
        all_labels = []
        all_probabilities = []

        with torch.no_grad():
            for batch in test_loader:
                url_features = batch['url_features'].to(device)
                html_features = batch['html_features'].to(device)
                ssl_features = batch['ssl_features'].to(device)
                labels = batch['label'].to(device)

                outputs = model(url_features, html_features, ssl_features)
                probabilities = torch.softmax(outputs, dim=1)[:, 1]
                _, predicted = torch.max(outputs, 1)

                all_predictions.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
                all_probabilities.extend(probabilities.cpu().numpy())

        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        metrics = {
            'accuracy': accuracy_score(all_labels, all_predictions),
            'precision': precision_score(all_labels, all_predictions),
            'recall': recall_score(all_labels, all_predictions),
            'f1_score': f1_score(all_labels, all_predictions),
            'roc_auc': roc_auc_score(all_labels, all_probabilities)
        }

        self.metrics = metrics
        return metrics

    def plot_confusion_matrix(self, y_true: np.ndarray, y_pred: np.ndarray):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        from sklearn.metrics import confusion_matrix
        cm = confusion_matrix(y_true, y_pred)

        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
        plt.title('æ··æ·†çŸ©é˜µ')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾')
        plt.ylabel('çœŸå®æ ‡ç­¾')
        plt.savefig('confusion_matrix.png')
        plt.close()

    def plot_roc_curve(self, y_true: np.ndarray, y_prob: np.ndarray):
        """ç»˜åˆ¶ROCæ›²çº¿"""
        from sklearn.metrics import roc_curve

        fpr, tpr, _ = roc_curve(y_true, y_prob)
        auc = roc_auc_score(y_true, y_prob)

        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, label=f'ROCæ›²çº¿ (AUC = {auc:.3f})')
        plt.plot([0, 1], [0, 1], 'k--', label='éšæœºåˆ†ç±»å™¨')
        plt.xlabel('å‡æ­£ç‡')
        plt.ylabel('çœŸæ­£ç‡')
        plt.title('ROCæ›²çº¿')
        plt.legend()
        plt.grid(True)
        plt.savefig('roc_curve.png')
        plt.close()

def main():
    parser = argparse.ArgumentParser(description='é’“é±¼ç½‘ç«™æ£€æµ‹å™¨è®­ç»ƒ')
    parser.add_argument('--data', type=str, default='phishing_dataset.csv', help='æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch_size', type=int, default=64, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--epochs', type=int, default=100, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=0.001, help='å­¦ä¹ ç‡')
    parser.add_argument('--save_model', type=str, default='best_model.pth', help='æ¨¡å‹ä¿å­˜è·¯å¾„')

    args = parser.parse_args()

    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        logger.info(f"GPU: {torch.cuda.get_device_name()}")
        logger.info(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        logger.info(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

    # æ•°æ®å¤„ç†
    logger.info("å¼€å§‹æ•°æ®å¤„ç†...")
    processor = DataProcessor()
    df = processor.load_data(args.data)

    if df.empty:
        logger.error("æ•°æ®åŠ è½½å¤±è´¥")
        return

    X, y = processor.preprocess_data(df)
    X_train, X_val, X_test, y_train, y_val, y_test = processor.split_data(X, y)

    # åˆ›å»ºæ•°æ®é›†
    train_features = processor.create_features_dict(X_train)
    val_features = processor.create_features_dict(X_val)
    test_features = processor.create_features_dict(X_test)

    train_dataset = PhishingDataset(train_features, y_train)
    val_dataset = PhishingDataset(val_features, y_val)
    test_dataset = PhishingDataset(test_features, y_test)

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)

    # åˆ›å»ºè®­ç»ƒå™¨
    logger.info("åˆ›å»ºè®­ç»ƒå™¨...")
    config = TrainingConfig()
    config.training_config['batch_size'] = args.batch_size
    config.training_config['num_epochs'] = args.epochs
    config.optimizer_config['lr'] = args.lr

    trainer = Trainer(config)

    # å¼€å§‹è®­ç»ƒ
    logger.info("å¼€å§‹è®­ç»ƒ...")
    start_time = time.time()

    trainer.train(train_loader, val_loader)

    training_time = time.time() - start_time
    logger.info(f"è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f} ç§’")

    # è¯„ä¼°æ¨¡å‹
    logger.info("è¯„ä¼°æ¨¡å‹...")
    evaluator = ModelEvaluator()
    metrics = evaluator.evaluate_model(trainer.model, test_loader, device)

    # æ‰“å°è¯„ä¼°ç»“æœ
    logger.info("=== æ¨¡å‹è¯„ä¼°ç»“æœ ===")
    for metric_name, value in metrics.items():
        logger.info(f"{metric_name}: {value:.4f}")

    # ç»˜åˆ¶è¯„ä¼°å›¾è¡¨
    logger.info("ç”Ÿæˆè¯„ä¼°å›¾è¡¨...")
    test_predictions = []
    test_labels = []
    test_probabilities = []

    trainer.model.eval()
    with torch.no_grad():
        for batch in test_loader:
            url_features = batch['url_features'].to(device)
            html_features = batch['html_features'].to(device)
            ssl_features = batch['ssl_features'].to(device)
            labels = batch['label'].to(device)

            outputs = trainer.model(url_features, html_features, ssl_features)
            probabilities = torch.softmax(outputs, dim=1)[:, 1]
            _, predicted = torch.max(outputs, 1)

            test_predictions.extend(predicted.cpu().numpy())
            test_labels.extend(labels.cpu().numpy())
            test_probabilities.extend(probabilities.cpu().numpy())

    evaluator.plot_confusion_matrix(np.array(test_labels), np.array(test_predictions))
    evaluator.plot_roc_curve(np.array(test_labels), np.array(test_probabilities))

    # ä¿å­˜ç»“æœ
    results = {
        'metrics': metrics,
        'training_time': training_time,
        'model_config': config.model_config,
        'training_config': config.training_config,
        'device': str(device),
        'gpu_info': {
            'name': torch.cuda.get_device_name() if torch.cuda.is_available() else 'CPU',
            'memory': torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0
        }
    }

    with open('training_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    logger.info("âœ… è®­ç»ƒå®Œæˆ!")
    logger.info(f"ğŸ“Š è¯„ä¼°æŒ‡æ ‡: {json.dumps(metrics, indent=2, ensure_ascii=False)}")
    logger.info(f"ğŸ’¾ æ¨¡å‹ä¿å­˜è‡³: {args.save_model}")
    logger.info(f"ğŸ“ˆ æ··æ·†çŸ©é˜µ: confusion_matrix.png")
    logger.info(f"ğŸ“ˆ ROCæ›²çº¿: roc_curve.png")
    logger.info(f"ğŸ“‹ è®­ç»ƒç»“æœ: training_results.json")

if __name__ == "__main__":
    main()